name: Database Migrations

on:
  push:
    branches: [ main, develop, staging ]
    paths:
      - 'function_app/migrations/**'
      - '.github/workflows/database-migrations.yml'
  workflow_dispatch:  # Allow manual triggering
    inputs:
      environment:
        description: 'Environment to run migrations on'
        required: true
        default: 'development'
        type: choice
        options:
          - development
          - staging
          - production

env:
  PYTHON_VERSION: '3.11'
  DB_NAME_DEV: 'ocrlab_dev'
  DB_NAME_STAGING: 'ocrlab_staging'
  DB_NAME_PROD: 'ocrlab'

jobs:
  run-migrations:
    name: Run Database Migrations
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r function_app/requirements.txt
          pip install alembic psycopg2-binary

      - name: Login to Azure
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Set environment for branch
        id: set-env
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "ENVIRONMENT=${{ github.event.inputs.environment }}" >> $GITHUB_ENV
          elif [ "${{ github.ref }}" == "refs/heads/main" ]; then
            echo "ENVIRONMENT=production" >> $GITHUB_ENV
          elif [ "${{ github.ref }}" == "refs/heads/staging" ]; then
            echo "ENVIRONMENT=staging" >> $GITHUB_ENV
          else
            echo "ENVIRONMENT=development" >> $GITHUB_ENV
          fi
          echo "Selected environment: ${{ env.ENVIRONMENT }}"

          # Set the database name based on the environment
          if [ "${{ env.ENVIRONMENT }}" == "production" ]; then
            echo "DB_NAME=${{ env.DB_NAME_PROD }}" >> $GITHUB_ENV
          elif [ "${{ env.ENVIRONMENT }}" == "staging" ]; then
            echo "DB_NAME=${{ env.DB_NAME_STAGING }}" >> $GITHUB_ENV
          else
            echo "DB_NAME=${{ env.DB_NAME_DEV }}" >> $GITHUB_ENV
          fi
          echo "Database Name: ${{ env.DB_NAME }}"

      - name: Get database connection string
        id: get-connection-string
        run: |
          # Get the database connection string from Azure Key Vault
          if [ "${{ env.ENVIRONMENT }}" == "production" ]; then
            CONNECTION_STRING=$(az keyvault secret show --name "DB-CONNECTION-STRING" --vault-name "ocrlabkv" --query value -o tsv)
          elif [ "${{ env.ENVIRONMENT }}" == "staging" ]; then
            CONNECTION_STRING=$(az keyvault secret show --name "DB-CONNECTION-STRING-STAGING" --vault-name "ocrlabkv" --query value -o tsv)
          else
            CONNECTION_STRING=$(az keyvault secret show --name "DB-CONNECTION-STRING-DEV" --vault-name "ocrlabkv" --query value -o tsv)
          fi
          
          # Set the connection string as an environment variable (masked in logs)
          echo "::add-mask::$CONNECTION_STRING"
          echo "DB_CONNECTION_STRING=$CONNECTION_STRING" >> $GITHUB_ENV

      - name: Create migrations directory if it doesn't exist
        run: |
          if [ ! -d "function_app/migrations" ]; then
            echo "Creating migrations directory"
            mkdir -p function_app/migrations
            
            # Initialize Alembic if not already initialized
            cd function_app
            if [ ! -f "migrations/env.py" ]; then
              echo "Initializing Alembic"
              alembic init migrations
              
              # Update alembic.ini with placeholder that will be replaced at runtime
              sed -i 's|sqlalchemy.url = .*|sqlalchemy.url = postgresql://user:pass@localhost/dbname|g' alembic.ini
            fi
          fi

      - name: Generate migration script (if needed)
        run: |
          cd function_app
          
          # Check if there are any model changes that need migration
          if [ -f "models.py" ]; then
            echo "Generating migration script"
            export PYTHONPATH=$PYTHONPATH:$(pwd)
            
            # Replace the connection string in alembic.ini at runtime
            sed -i "s|sqlalchemy.url = .*|sqlalchemy.url = ${{ env.DB_CONNECTION_STRING }}|g" alembic.ini
            
            # Generate migration with a timestamp and descriptive message
            alembic revision --autogenerate -m "auto_migration_$(date +%Y%m%d%H%M%S)"
          else
            echo "No models.py file found, skipping migration generation"
          fi

      - name: Run database migrations
        run: |
          cd function_app
          
          # Replace the connection string in alembic.ini at runtime
          sed -i "s|sqlalchemy.url = .*|sqlalchemy.url = ${{ env.DB_CONNECTION_STRING }}|g" alembic.ini
          
          # Run the migrations
          echo "Running database migrations"
          alembic upgrade head

      - name: Verify migrations
        run: |
          cd function_app
          
          # Check migration status
          echo "Checking migration status"
          alembic current
          
          # List migration history
          echo "Migration history:"
          alembic history

      - name: Create database backup (production only)
        if: env.ENVIRONMENT == 'production'
        run: |
          echo "Creating database backup before migrations"
          
          # Extract connection details from connection string
          DB_HOST=$(echo ${{ env.DB_CONNECTION_STRING }} | sed -n 's/.*@\([^:]*\).*/\1/p')
          DB_USER=$(echo ${{ env.DB_CONNECTION_STRING }} | sed -n 's/.*:\/\/\([^:]*\).*/\1/p')
          
          # Create a backup using pg_dump
          BACKUP_FILE="${{ env.DB_NAME }}_backup_$(date +%Y%m%d%H%M%S).sql"
          PGPASSWORD=$(echo ${{ env.DB_CONNECTION_STRING }} | sed -n 's/.*:\([^@]*\)@.*/\1/p') pg_dump -h $DB_HOST -U $DB_USER -d ${{ env.DB_NAME }} -f $BACKUP_FILE
          
          # Upload backup to Azure Blob Storage
          az storage blob upload --account-name ocrlabstorage --container-name db-backups --name $BACKUP_FILE --file $BACKUP_FILE --auth-mode login 